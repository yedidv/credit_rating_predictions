{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "actual-translator",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Read-in-Data\" data-toc-modified-id=\"Read-in-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Read in Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-in-excel-files-combining-ticker-symbols-with-the-IQID\" data-toc-modified-id=\"Read-in-excel-files-combining-ticker-symbols-with-the-IQID-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Read in excel files combining ticker symbols with the IQID</a></span></li><li><span><a href=\"#Read-in-independent-variables,-join-tickers\" data-toc-modified-id=\"Read-in-independent-variables,-join-tickers-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Read in independent variables, join tickers</a></span></li><li><span><a href=\"#Join-in-the-credit-rating-data\" data-toc-modified-id=\"Join-in-the-credit-rating-data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Join in the credit rating data</a></span></li></ul></li><li><span><a href=\"#Generate-Model-Data\" data-toc-modified-id=\"Generate-Model-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Generate Model Data</a></span></li><li><span><a href=\"#Generate-Models\" data-toc-modified-id=\"Generate-Models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Generate Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Support-Vector-Machines\" data-toc-modified-id=\"Support-Vector-Machines-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Support Vector Machines</a></span></li><li><span><a href=\"#Random-Forest-Classifier\" data-toc-modified-id=\"Random-Forest-Classifier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Random Forest Classifier</a></span></li></ul></li><li><span><a href=\"#Prediction-Function\" data-toc-modified-id=\"Prediction-Function-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Prediction Function</a></span></li><li><span><a href=\"#Plot-Accuracy\" data-toc-modified-id=\"Plot-Accuracy-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Plot Accuracy</a></span></li><li><span><a href=\"#See-values\" data-toc-modified-id=\"See-values-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>See values</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-endorsement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T14:32:53.466938Z",
     "start_time": "2021-03-18T14:32:52.797595Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import plotly.graph_objects as go \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-subscription",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T17:30:07.606588Z",
     "start_time": "2021-03-13T17:30:07.540321Z"
    }
   },
   "source": [
    "## Read in Data\n",
    "\n",
    "---\n",
    "### Read in excel files combining ticker symbols with the IQID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-volume",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T14:32:53.977028Z",
     "start_time": "2021-03-18T14:32:53.735946Z"
    }
   },
   "outputs": [],
   "source": [
    "ids= pd.DataFrame() \n",
    "## Read in ticker symbols\n",
    "for i in range(1, 6): \n",
    "    df = pd.read_excel('capiq_data/in_process_ids/ids {}.xlsx'.format(i),\n",
    "                       engine='openpyxl')[['ID', 'IQID', 'IQ Name']]\n",
    "    ids = pd.concat([ids, df]) \n",
    "\n",
    "## See if there are any duplicates \n",
    "print(ids.duplicated().sum()) \n",
    "## See if there are any nulls \n",
    "print(ids.isna().sum()) \n",
    "ids.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-seminar",
   "metadata": {},
   "source": [
    "### Read in independent variables, join tickers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-electric",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T14:32:55.065708Z",
     "start_time": "2021-03-18T14:32:54.999389Z"
    }
   },
   "outputs": [],
   "source": [
    "## Join IQID for inds so we can see the Ticker and the name \n",
    "\n",
    "ind_df = pd.read_csv('small_df.csv') \n",
    "\n",
    "ind_df = ind_df.merge(ids, on = ['IQID', 'IQ Name']) \n",
    "ind_df.drop(['Unnamed: 0', 'IQ Name', 'IQID', \n",
    "            'quarter'], axis = 1, inplace = True) \n",
    "\n",
    "## The data is quarterly, but we need to lok at it annually. \n",
    "## This means we have to take the mean of the data for all the quarters \n",
    "ind_df = ind_df.groupby(['year', 'ID']).mean().reset_index()\n",
    "                      \n",
    "ind_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-gregory",
   "metadata": {},
   "source": [
    "### Join in the credit rating data\n",
    "\n",
    "We want an inner join so we only keep the companies that we have the credit rating for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-enforcement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T14:32:56.816670Z",
     "start_time": "2021-03-18T14:32:56.761707Z"
    }
   },
   "outputs": [],
   "source": [
    "## Join in the credit Ratings Data\n",
    "credit_ratings = pd.read_csv('credit.csv')[['Year', 'TickerSymbol',\n",
    "                                            'DomesticLTICRSPMthlyAvg']]\n",
    "credit_ratings.rename({'DomesticLTICRSPMthlyAvg': 'rating'}, inplace = True, axis = 1)  \n",
    "\n",
    "## Add credit ratings to df  \n",
    "tot_df = credit_ratings.merge(ind_df, how = 'inner', \n",
    "                             left_on = ['Year', 'TickerSymbol'], \n",
    "                             right_on = ['year', 'ID'])\n",
    "tot_df.drop(['Year', 'TickerSymbol'], axis = 1, inplace = True) \n",
    "\n",
    "tot_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-switzerland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T14:32:59.241292Z",
     "start_time": "2021-03-18T14:32:57.738084Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_df_clean = pd.DataFrame() \n",
    "\n",
    "\n",
    "\n",
    "for ticker in tqdm(tot_df['ID'].unique()): \n",
    "    \n",
    "    \n",
    "    ## small df is all the rows with the ticker, sort by year \n",
    "    small_df = tot_df[tot_df['ID'] == ticker].sort_values(by = 'year',\n",
    "                                                             ascending = True)\n",
    "    \n",
    "    \n",
    "    ## Insert a lead rating column. This is the predictor column, \n",
    "    ## as we are trying to predict the credit rating for the next year\n",
    "    small_df.insert(loc = 0, column = 'lead_rating', \n",
    "               value = small_df.rating.shift(1)) \n",
    "    \n",
    "    \n",
    "    ## Set the index as the year and the ticker. \n",
    "    small_df.set_index(['year', 'ID'], inplace = True) \n",
    "    \n",
    "    ## Take the difference between rows. We are looking to find \n",
    "    ## differences in credit rating, so we are going to compare it to \n",
    "    ## differences in dependent variables. \n",
    "    ## We can then drop the nulls. \n",
    "    small_df = small_df.diff().dropna()  \n",
    "    \n",
    "    tot_df_clean = pd.concat([tot_df_clean, small_df], axis = 0) \n",
    "\n",
    "tot_df_clean.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-onion",
   "metadata": {},
   "source": [
    "## Generate Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-hampshire",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T14:33:00.098843Z",
     "start_time": "2021-03-18T14:33:00.094377Z"
    }
   },
   "outputs": [],
   "source": [
    "lead_rating = tot_df_clean['lead_rating'].to_numpy()\n",
    "\n",
    "\n",
    "lead_rating[lead_rating == 0] = 0\n",
    "lead_rating[(lead_rating > 0) & (lead_rating <= 1)] = 1 \n",
    "lead_rating[(lead_rating < 0) & (lead_rating >= -1)] = -1 \n",
    "lead_rating[lead_rating > 1] = 2 \n",
    "lead_rating[lead_rating < -1] = -2\n",
    "tot_df_clean['rating'] = tot_df_clean['lead_rating']\n",
    "tot_df_clean['lead_rating'] = lead_rating\n",
    "\n",
    "full_df = tot_df_clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-failure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T14:33:01.315924Z",
     "start_time": "2021-03-18T14:33:01.211461Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_df_clean.lead_rating.value_counts().to_frame().style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-delivery",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.039Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample \n",
    "\n",
    "## Resample the data\n",
    "\n",
    "rating_0 = tot_df_clean[tot_df_clean.lead_rating ==0 ]\n",
    "tot_df_clean_sampled = tot_df_clean[tot_df_clean.lead_rating !=0 ]\n",
    "rating_0 = resample(rating_0, \n",
    "                   replace = True, \n",
    "                   n_samples = 150,\n",
    "                    random_state = 123) \n",
    "\n",
    "tot_df_clean = pd.concat([rating_0, \n",
    "                          tot_df_clean_sampled], axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-pillow",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.041Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "## Split into x and y\n",
    "x = tot_df_clean.drop(['lead_rating'], axis = 1) \n",
    "\n",
    "y_numeric = tot_df_clean['rating'] \n",
    "y = tot_df_clean['lead_rating'] \n",
    "\n",
    "\n",
    "## Normalize the data, but we don't need to normalize the \n",
    "## dependent variable\n",
    "x = (x - x.mean()) / (x.std())\n",
    "\n",
    "\n",
    "## We'll set aside 10% of the data for testing\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    train_size = 0.9, \n",
    "                                                    random_state = 5)\n",
    "\n",
    "train_x_num, test_x_num, train_y_num, test_y_num = train_test_split(x, y_numeric, train_size = 0.9, random_state = 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-powell",
   "metadata": {},
   "source": [
    "## Generate Models \n",
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-insertion",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.185Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def SVM_Fit(train_x, train_y, kernel,\n",
    "            params = [10**x for x in np.arange(-1,3,0.9)]): \n",
    "    '''Fit the SVM Machine given the kernel type, parameters, \n",
    "    data''' \n",
    "    \n",
    "    if kernel == 'linear': \n",
    "        parameters = {'C': params} \n",
    "    else: \n",
    "        parameters = {'C': params, \n",
    "                     'gamma': params} \n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits = 5, \n",
    "                                n_repeats = 5) \n",
    "    \n",
    "    model = GridSearchCV(estimator = SVC(kernel = kernel), \n",
    "                        param_grid = parameters, \n",
    "                        cv = 2, \n",
    "                        verbose = 1) \n",
    "    \n",
    "    model.fit(x, y) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-three",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-delight",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.316Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 200) \n",
    "rf.get_params()\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                              param_distributions = random_grid, \n",
    "                              n_iter = 100, cv = 5, verbose = 2, \n",
    "                              random_state = 200, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-functionality",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-species",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.437Z"
    }
   },
   "outputs": [],
   "source": [
    "def Predict(fitted_model, test_x, test_y, name):\n",
    "    prediction = fitted_model.predict(test_x) \n",
    "    score = accuracy_score(prediction, test_y) \n",
    "    prediction = pd.DataFrame({'prediction_{}'.format(name): prediction})\n",
    "    print('The {} Model Score is: {}'.format(name, score)) \n",
    "    return prediction, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-strand",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.439Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make predictions\n",
    "sigmoid = SVM_Fit(train_x, train_y, 'sigmoid') \n",
    "rbf = SVM_Fit(train_x, train_y, 'rbf') \n",
    "linear = SVM_Fit(train_x, train_y,'linear')\n",
    "#poly = SVM_Fit(train_x, train_y, 'poly') \n",
    "poly = SVC(kernel = 'poly').fit(train_x, train_y)\n",
    "\n",
    "rf_random.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-reporter",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.443Z"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_predict, sigmoid_score = Predict(sigmoid, test_x, test_y, 'sigmoid') \n",
    "lin_predict, lin_score = Predict(linear, test_x, test_y, 'linear') \n",
    "poly_predict, poly_score = Predict(poly, test_x, test_y, 'poly') \n",
    "rbf_predict, rbf_score = Predict(rbf, test_x, test_y, 'radial') \n",
    "\n",
    "\n",
    "random_predict, random_score = Predict(rf_random, test_x, test_y, \n",
    "                                      'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-amateur",
   "metadata": {},
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-galaxy",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.553Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "model_names = ['Sigmoid SVC', 'Radial SVC', 'Linear SVC', 'Polynomial SVC',\n",
    " 'Random Forests']\n",
    "\n",
    "model_accuracy = [sigmoid_score, rbf_score, lin_score, poly_score, random_score]\n",
    "\n",
    "fig.add_trace(go.Bar(x = model_names, \n",
    "                    y = model_accuracy, \n",
    "                    text = model_accuracy, \n",
    "                    textposition = 'auto'))\n",
    "fig.update_layout(title = 'Model Accuracy Scores')\n",
    "\n",
    "fig.update_yaxes(title_text = 'Accuracy Score') \n",
    "fig.update_xaxes(title_text = \"Model\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-thailand",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.555Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "## OLS Linear Regression\n",
    "ols = LinearRegression().fit(train_x_num, train_y_num)\n",
    "ols_prediction = ols.predict(test_x_num)\n",
    "ols_r2 = mean_squared_error( test_y_num,ols_prediction) \n",
    "ols_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-mozambique",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.557Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def ContinuousPrediction(model, train_x, train_y, test_x, test_y): \n",
    "\n",
    "    params = [10**x for x in np.arange(-1,3,0.9)]\n",
    "\n",
    "    model = GridSearchCV(estimator= model, param_grid = dict(alpha = params), cv = 5, verbose = 1)\n",
    "\n",
    "    model.fit(train_x, train_y) \n",
    "\n",
    "    prediction = model.predict(test_x) \n",
    "\n",
    "    r_2 = mean_squared_error(test_y, prediction) \n",
    "\n",
    "    return model, prediction, r_2 \n",
    "\n",
    "lasso, lasso_predict, lasso_r2 = ContinuousPrediction(Lasso(), train_x_num, train_y_num, test_x_num, test_y_num)\n",
    "ridge, ridge_predict, ridge_r2 = ContinuousPrediction(Ridge(), train_x_num, train_y_num, test_x_num, test_y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-alarm",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.559Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The Lasso Prediction R2 Score is: {}'.format(lasso_r2) ) \n",
    "print('The Ridge Prediction R2 Score is: {}'.format(ridge_r2) ) \n",
    "print('The OLS Prediction R2 Score is: {}'.format(ols_r2) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-rebate",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.561Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "def SVM_Fit_Num(train_x, train_y, kernel,\n",
    "            params = [10**x for x in np.arange(-1,3,0.9)]): \n",
    "    '''Fit the SVM Machine given the kernel type, parameters, \n",
    "    data''' \n",
    "    \n",
    "    if kernel == 'linear': \n",
    "        parameters = {'C': params} \n",
    "    else: \n",
    "        parameters = {'C': params, \n",
    "                     'gamma': params} \n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits = 5, \n",
    "                                n_repeats = 5) \n",
    "    \n",
    "    model = GridSearchCV(estimator = SVR(kernel = kernel), \n",
    "                        param_grid = parameters, \n",
    "                        cv = 2, \n",
    "                        verbose = 1) \n",
    "    \n",
    "    model.fit(train_x, train_y) \n",
    "\n",
    "    return model\n",
    "\n",
    "def PredictNum(fitted_model, test_x, test_y, name):\n",
    "    prediction = fitted_model.predict(test_x) \n",
    "    score = mean_squared_error(test_y, prediction) \n",
    "    prediction = pd.DataFrame({'prediction_{}'.format(name): prediction})\n",
    "    print('The {} Model Score is: {}'.format(name, score)) \n",
    "    return prediction, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-letters",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.562Z"
    }
   },
   "outputs": [],
   "source": [
    "linear_num = SVM_Fit_Num(train_x_num, train_y_num, 'linear') \n",
    "#poly_num, poly_predict_num, poly_score_num = SVM_Fit_Num(train_x_num, train_y_num, test_x_num, test_y_num, 'poly') \n",
    "poly_num = SVR().fit(train_x_num, train_y_num) \n",
    "rbf_num = SVM_Fit_Num(train_x_num, train_y_num, 'rbf') \n",
    "sigmoid_num = SVM_Fit_Num(train_x_num, train_y_num,'sigmoid') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-force",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.564Z"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_predict_num, sigmoid_score_num = PredictNum(sigmoid_num, test_x_num, test_y_num, 'Sigmoid') \n",
    "rbf_predict_num, rbf_score_num = PredictNum(rbf_num, test_x_num, test_y_num, 'Radial') \n",
    "poly_predict_num, poly_score_num = PredictNum(poly_num, test_x_num, test_y_num, 'Polynomial')\n",
    "lin_predict_num, lin_score_num = PredictNum(linear_num, test_x_num, test_y_num, 'Linear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-citizen",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.567Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "model_names = ['Sigmoid SVM', 'Radial SVM', 'Linear SVM', 'Polynomial SVM', 'OLS', 'Lasso', 'Ridge']\n",
    "\n",
    "model_accuracy = [sigmoid_score_num, rbf_score_num, lin_score_num, poly_score_num, ols_r2, lasso_r2, ridge_r2]\n",
    "\n",
    "fig.add_trace(go.Bar(x = model_names, \n",
    "                    y = model_accuracy, \n",
    "                    text = model_accuracy, \n",
    "                    textposition = 'auto'))\n",
    "fig.update_layout(title = 'Model Accuracy Scores Numeric Prediction')\n",
    "\n",
    "fig.update_yaxes(title_text = 'Mean Squared Error') \n",
    "fig.update_xaxes(title_text = \"Model\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-ethernet",
   "metadata": {},
   "source": [
    "## See values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-sponsorship",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:33:04.632Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "from cleaning_plots import * \n",
    "fig, metrics = PlotReg(full_df,\n",
    "        dep_cols = ['lead_rating', 'rating']).Plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-surrey",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.680Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-singing",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-18T14:31:14.681Z"
    }
   },
   "outputs": [],
   "source": [
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-consumer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}